import json
from typing import List
import requests


class TextCleaningEngine:
    
    def __init__(self, base_url: str = 'http://localhost:11434', model: str = 'qwen2.5:7b'):
        self.base_url = base_url.rstrip('/')
        self.model = model
        self._setup_system_prompts()
    
    def _setup_system_prompts(self) -> None:
        self.cleaning_prompts = {
            "sentence_repair": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬ä¿®å¤ä¸“å®¶ã€‚è¯·å¯¹è¾“å…¥æ–‡æœ¬æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

            1. **åˆ é™¤ä¸è¿è´¯çš„çŸ­å¥ç‰‡æ®µ** - ç§»é™¤æ— æ„ä¹‰çš„æ–­å¥ã€ä¸å®Œæ•´çš„è¡¨è¾¾
            2. **ä¿®å¤è¯­æ³•é”™è¯¯** - ä¿®æ­£ä¸»è°“ä¸ä¸€è‡´ã€æ—¶æ€é”™è¯¯ç­‰
            3. **ä¼˜åŒ–å¥å­æµç•…åº¦** - è°ƒæ•´è¯­åºï¼Œç¡®ä¿é€»è¾‘è¿è´¯
            4. **ä¿æŒè¯­ä¹‰å®Œæ•´æ€§** - ä¸æ”¹å˜åŸæ–‡çš„æ ¸å¿ƒå«ä¹‰
            5. **å¤„ç†ç‰¹æ®Šç¬¦å·** - åˆç†ä¿ç•™å¿…è¦çš„æ ‡ç‚¹ï¼Œç§»é™¤å¹²æ‰°ç¬¦å·

            è¾“å‡ºè¦æ±‚ï¼š
            - ç›´æ¥è¿”å›æ¸…æ´—åçš„ä¸€æ®µå®Œæ•´æ­£æ–‡æ–‡æœ¬
            - ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°
            - ä¿æŒæ®µè½ç»“æ„å’Œé‡è¦æ ¼å¼
            - ç¡®ä¿æ–‡æœ¬è‡ªç„¶é€šé¡º""",

                        "paragraph_reconstruction": """ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬é‡æ„ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œæ·±åº¦ä¿®å¤ï¼š

            å¤„ç†é‡ç‚¹ï¼š
            ğŸ”¹ è¯†åˆ«å¹¶åˆ é™¤ä¸è¿ç»­çš„çŸ­å¥ç¢ç‰‡å°æ ‡é¢˜
            ğŸ”¹ åˆå¹¶è¯­ä¹‰ç›¸å…³çš„çŸ­å¥
            ğŸ”¹ é‡å»ºé€»è¾‘è¿æ¥å…³ç³»
            ğŸ”¹ ä¼˜åŒ–æ–‡æœ¬æµç•…æ€§å’Œå¯è¯»æ€§
            ğŸ”¹ ä¿æŒä¸“ä¸šæœ¯è¯­å’Œå…³é”®ä¿¡æ¯
            - åˆ é™¤ä¸ä½œè€…ä¿¡æ¯ç›¸å…³çš„å†…å®¹ã€ä»¥åŠå…³é”®è¯
            - åˆ é™¤ç±»ä¼¼'ä¸­å›½å‘ä½œæ€§ç¡ç—…è¯Šæ–­ä¸æ²»ç–—æŒ‡å—(2022ç‰ˆ),ä¸­ååŒ»å­¦ä¼šç¥ç»ç—…å­¦åˆ†ä¼šç¡çœ éšœç¢å­¦ç»„'ç­‰èƒŒæ™¯ä¿¡æ¯

            é‡æ„åŸåˆ™ï¼š
            - è¯­ä¹‰è¿è´¯æ€§ä¼˜å…ˆ
            - ä¿æŒåŸæ–‡é£æ ¼ä¸å˜
            - ä¿®å¤å¹¶ä¸é‡å†™å†…å®¹
            - ç¡®ä¿æŠ€æœ¯å‡†ç¡®æ€§
            - ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°"""
        }
    
    def _call_model_api(self, prompt: str, text_chunk: str, system_prompt_key: str) -> str:
        url = f"{self.base_url}/api/generate"
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "system": self.cleaning_prompts[system_prompt_key],
            "stream": False,
            "options": {
                "temperature": 0.1,
                "top_p": 0.8,
                "num_predict": min(len(text_chunk) * 2, 4000),
                "repeat_penalty": 1.2
            }
        }
        
        try:
            response = requests.post(
                url,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=60
            )
            response.raise_for_status()
            
            result = response.json()
            return result.get('response', '').strip()
            
        except requests.exceptions.RequestException as e:
            print(f"APIè°ƒç”¨å¤±è´¥: {e}")
            return text_chunk
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            return text_chunk
        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯: {e}")
            return text_chunk
    
    def _create_cleaning_prompt(self, text_chunk: str) -> str:
        return f"éœ€è¦å¤„ç†çš„æ–‡æœ¬ï¼š\n{text_chunk}\n\nè¯·è¿”å›æ¸…æ´—åçš„æ–‡æœ¬ï¼š"
    
    def _create_reconstruction_prompt(self, text_chunk: str) -> str:
        return f"éœ€è¦å¤„ç†çš„æ–‡æœ¬ï¼š\n{text_chunk}\n\nè¯·è¿”å›é‡æ„åçš„æ–‡æœ¬ï¼š"
    
    def clean_text_chunk(self, text_chunk: str) -> str:
        if not text_chunk or not text_chunk.strip():
            return text_chunk
            
        cleaning_prompt = self._create_cleaning_prompt(text_chunk)
        cleaned_text = self._call_model_api(cleaning_prompt, text_chunk, "sentence_repair")
        
        reconstruction_prompt = self._create_reconstruction_prompt(cleaned_text)
        final_text = self._call_model_api(reconstruction_prompt, cleaned_text, "paragraph_reconstruction")
        
        return final_text

    def batch_clean_text(self, text_chunks: List[str]) -> List[str]:
        return [self.clean_text_chunk(chunk) for chunk in text_chunks]


def main():
    engine = TextCleaningEngine()
    
    sample_texts = [
        "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚å®ƒåŒ…å«ä¸€äº›ä¸çš„å¥å­ï¼Œå’Œä¸€äº›è¯­æ³•è¯¯ã€‚å¦ä¸€ä¸ªä¾‹å­ï¼è¿™é‡Œæœ‰æ›´å¤šçš„é—®é¢˜ï¼Œæ¯”å¦‚æ ‡,.kç¬¦å·çš„ä½¿ä¸å½“ï¼Ÿ",
        "å¦ä¸€ä¸ªæµ‹è¯•æ®µè½ã€‚å¥å­ä¸å®Œæ•´ã€‚æ ‡ç‚¹ç¬¦å·é”™è¯¯ï¼Œè¿˜æœ‰é‡å¤çš„å†…å®¹é‡å¤çš„å†…å®¹ã€‚"
    ]
    
    print("å¼€å§‹æ–‡æœ¬æ¸…æ´—...")
    
    for i, text in enumerate(sample_texts, 1):
        print(f"\n--- ç¤ºä¾‹ {i} ---")
        print(f"åŸå§‹æ–‡æœ¬: {text}")
        
        cleaned_text = engine.clean_text_chunk(text)
        print(f"æ¸…æ´—å: {cleaned_text}")


if __name__ == "__main__":
    main()
